{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Visualizing a Decision Tree"
      ],
      "metadata": {
        "id": "inVbuORq_5td"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Like SVMs, Decision Trees are versatile Machine Learning algorithms that can per‐\n",
        "form both classification and regression tasks, and even multioutput tasks. They are\n",
        "very powerful algorithms, capable of fitting complex datasets. For example you trained a DecisionTreeRegressor model on the California housing dataset,\n",
        "fitting it perfectly (actually overfitting it).\n",
        "Decision Trees are also the fundamental components of Random Forests , which are among the most powerful Machine Learning algorithms available\n",
        "today.\n",
        "In this chapter we will start by discussing how to train, visualize, and make predic‐\n",
        "tions with Decision Trees. Then we will go through the CART training algorithm\n",
        "used by Scikit-Learn, and we will discuss how to regularize trees and use them for**"
      ],
      "metadata": {
        "id": "jUFzHSl4AKR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "iris = load_iris()\n",
        "X = iris.data[:, 2:] # petal length and width\n",
        "y = iris.target\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
        "tree_clf.fit(X, y)"
      ],
      "metadata": {
        "id": "Fu31cucd_q2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### You can visualize the trained Decision Tree by first using the export_graphviz()\n",
        "#### method to output a graph definition file called iris_tree.dot:"
      ],
      "metadata": {
        "id": "WDzpM4E1AR5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "export_graphviz(\n",
        " tree_clf,\n",
        " out_file=\"iris_tree.dot\",\n",
        " feature_names=iris.feature_names[2:],\n",
        " class_names=iris.target_names,\n",
        " rounded=True,\n",
        " filled=True\n",
        " )\n"
      ],
      "metadata": {
        "id": "qfiOOkzG_q90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Source\n",
        "Source.from_file(\"iris_tree.dot\")"
      ],
      "metadata": {
        "id": "MzW9vwWF_rEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import  plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = iris.data[:, 2:]  # petal length and width\n",
        "y = iris.target\n",
        "\n",
        "# Create and fit the decision tree classifier\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
        "tree_clf.fit(X, y)\n",
        "\n",
        "# Plot the decision tree\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_tree(tree_clf, filled=True, feature_names=iris.feature_names[2:], class_names=iris.target_names, rounded=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "17pMqZYZ_rLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='k', s=70)\n",
        "plt.xlabel('Petal Length (cm)')\n",
        "plt.ylabel('Petal Width (cm)')\n",
        "plt.title('Scatter Plot of Iris Dataset')\n",
        "plt.colorbar(label='Class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4f5oqpnZ_rSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making **Predictions**"
      ],
      "metadata": {
        "id": "b1vvOmTGAgc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let’s see how the tree represented makes predictions. Suppose you find\n",
        "an iris flower and you want to classify it. You start at the root node (depth 0, at the\n",
        "top): this node asks whether the flower’s petal length is smaller than 2.45 cm. If it is,\n",
        "then you move down to the root’s left child node (depth 1, left). In this case, it is a leaf\n",
        "node (i.e., it does not have any children nodes), so it does not ask any questions: you\n",
        "can simply look at the predicted class for that node and the Decision Tree predicts\n",
        "that your flower is an Iris-Setosa (class=setosa).\n",
        "Now suppose you find another flower, but this time the petal length is greater than\n",
        "2.45 cm. You must move down to the root’s right child node (depth 1, right), which is\n",
        "not a leaf node, so it asks another question: is the petal width smaller than 1.75 cm? If\n",
        "it is, then your flower is most likely an Iris-Versicolor (depth 2, left). If not, it is likely\n",
        "an Iris-Virginica (depth 2, right). It’s really that simple.**"
      ],
      "metadata": {
        "id": "VHiWk8sAAoxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A node’s samples attribute counts how many training instances it applies to. For\n",
        "example, 100 training instances have a petal length greater than 2.45 cm (depth 1,\n",
        "right), among which 54 have a petal width smaller than 1.75 cm (depth 2, left). A\n",
        "node’s value attribute tells you how many training instances of each class this node\n",
        "applies to: for example, the bottom-right node applies to 0 Iris-Setosa, 1 Iris\u0002Versicolor, and 45 Iris-Virginica. Finally, a node’s gini attribute measures its impur‐\n",
        "ity: a node is “pure” (gini=0) if all training instances it applies to belong to the same\n",
        "class. For example, since the depth-1 left node applies only to Iris-Setosa training\n",
        "instances, it is pure and its gini score is 0. ‐\n",
        "rithm computes the gini score Gi\n",
        " of the ith node. For example, the depth-2 left node\n",
        "has a gini score equal to 1 – (0/54)2\n",
        " – (49/54)2\n",
        " – (5/54)2 ≈ 0.168. Another impurity\n",
        "measure is discussed shortly.\n",
        ". Gini impurity\n",
        "Gi\n",
        "= 1 − ∑\n",
        "k = 1\n",
        "n\n",
        "pi, k\n",
        "2\n",
        "• pi,k\n",
        " is the ratio of class k instances among the training instances in the i\n",
        "th node.**"
      ],
      "metadata": {
        "id": "_GR-N2_AAqDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf.predict_proba([[5, 1.5]])"
      ],
      "metadata": {
        "id": "QjLtsH5j_rZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf.predict([[5, 1.5]])\n"
      ],
      "metadata": {
        "id": "AEMEvC_2_re9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gigbgDwx_rjH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}